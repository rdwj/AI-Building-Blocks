# STIG to Ansible Playbook Generator Configuration
# Copy this file to .env and adjust the values for your setup

# LLM API Configuration (Required)
LLAMA_3_2_URL=http://localhost:11434/v1/completions
LLAMA_3_2_API_KEY=your_api_key_here

# Performance Settings - Adjust based on your GPU capacity
# Start with MAX_CONCURRENT_REQUESTS=1 for smaller GPUs
# Increase gradually as your hardware allows
MAX_CONCURRENT_REQUESTS=1
BATCH_SIZE=5
INTER_BATCH_DELAY=1.0

# LLM Settings
LLM_TIMEOUT=30
LLM_MAX_RETRIES=3
LLM_TEMPERATURE=0.3

# Workflow Settings
ENABLE_STEP_4_DOCUMENTATION=true
ENABLE_DEBUG_OUTPUT=false

# Output Settings
OUTPUT_BASE_DIR=playbooks
PRESERVE_FAILED_OUTPUTS=true

# GPU Capacity Guidelines:
# Small GPU (< 8GB):   MAX_CONCURRENT_REQUESTS=1, BATCH_SIZE=3-5,  INTER_BATCH_DELAY=1.0-2.0
# Medium GPU (8-16GB): MAX_CONCURRENT_REQUESTS=3, BATCH_SIZE=5-10, INTER_BATCH_DELAY=0.5-1.0
# Large GPU (16GB+):   MAX_CONCURRENT_REQUESTS=5+, BATCH_SIZE=10+, INTER_BATCH_DELAY=0.1-0.5