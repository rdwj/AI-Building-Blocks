# Environment variables for STIG to Ansible Playbook Generator

# LLM Configuration
LLAMA_3_2_URL=http://localhost:11434/api/generate
# LLAMA_3_2_URL=https://your-llama-endpoint.com/api/v1/generate

# Optional: API keys for other LLM providers
# OPENAI_API_KEY=your_openai_key_here
# ANTHROPIC_API_KEY=your_anthropic_key_here

# Output Configuration
OUTPUT_DIR=./playbooks
FINDINGS_DIR=./findings

# Processing Limits
MAX_FINDINGS_PER_RUN=50
LLM_REQUEST_TIMEOUT=30
