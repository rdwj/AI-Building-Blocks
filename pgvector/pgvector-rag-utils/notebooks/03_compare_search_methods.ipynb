{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Vector Search vs Hybrid Search\n",
    "\n",
    "This notebook demonstrates the differences between pure vector (dense) search and hybrid search that combines dense and sparse vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "from pgvector_rag import PGVectorRAG\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Set up plotting\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize connections\n",
    "conn_params = {\n",
    "    \"host\": os.getenv('DB_HOST', 'postgres-pgvector.pgvector.svc.cluster.local'),\n",
    "    \"port\": int(os.getenv('DB_PORT', '5432')),\n",
    "    \"database\": os.getenv('DB_NAME', 'vectordb'),\n",
    "    \"user\": os.getenv('DB_USER', 'vectoruser'),\n",
    "    \"password\": os.getenv('DB_PASSWORD', 'vectorpass')\n",
    "}\n",
    "\n",
    "# API configurations\n",
    "NOMIC_URL = os.getenv('NOMIC_EMBED_URL')\n",
    "if NOMIC_URL and not NOMIC_URL.endswith('/v1'):\n",
    "    NOMIC_URL = f\"{NOMIC_URL}/v1\"\n",
    "NOMIC_API_KEY = os.getenv('NOMIC_EMBED_API_KEY')\n",
    "NOMIC_MODEL = os.getenv('NOMIC_EMBED_MODEL_NAME')\n",
    "\n",
    "# Initialize RAG client\n",
    "rag = PGVectorRAG(conn_params)\n",
    "PROJECT_ID = os.getenv('PROJECT_ID', 'demo_project')\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def get_embedding(text: str) -> np.ndarray:\n",
    "    \"\"\"Get dense embedding for text\"\"\"\n",
    "    response = requests.post(\n",
    "        f\"{NOMIC_URL}/embeddings\",\n",
    "        headers={\n",
    "            'Authorization': f\"Bearer {NOMIC_API_KEY}\",\n",
    "            'Content-Type': 'application/json'\n",
    "        },\n",
    "        json={\n",
    "            'model': NOMIC_MODEL,\n",
    "            'input': text\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return np.array(data['data'][0]['embedding'])\n",
    "    else:\n",
    "        raise Exception(f\"Error getting embedding: {response.status_code}\")\n",
    "\n",
    "def get_sparse_embedding(text: str) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Generate sparse embedding (mock implementation).\n",
    "    In production, use SPLADE, BM25, or similar.\n",
    "    \"\"\"\n",
    "    # Simple TF-IDF-like approach for demonstration\n",
    "    words = text.lower().split()\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    # Convert to sparse vector format\n",
    "    sparse_vec = {}\n",
    "    for word, count in word_counts.items():\n",
    "        # Simple hash to get \"token ID\"\n",
    "        token_id = abs(hash(word)) % 30000\n",
    "        # TF-IDF-like weight (simplified)\n",
    "        weight = count * (1.0 / len(words))\n",
    "        sparse_vec[token_id] = weight\n",
    "    \n",
    "    return sparse_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's add some test documents with both dense and sparse embeddings\n",
    "test_documents = [\n",
    "    {\n",
    "        \"text\": \"PGVector is a PostgreSQL extension for vector similarity search. It supports multiple distance metrics including L2, inner product, and cosine distance.\",\n",
    "        \"topic\": \"database\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Vector databases enable semantic search by storing and querying high-dimensional embeddings generated by machine learning models.\",\n",
    "        \"topic\": \"ml\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The cosine similarity metric measures the angle between two vectors, making it useful for comparing document embeddings regardless of their magnitude.\",\n",
    "        \"topic\": \"math\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"PostgreSQL provides robust support for JSON data types and full-text search capabilities, making it versatile for modern applications.\",\n",
    "        \"topic\": \"database\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Hybrid search combines dense vector search with sparse retrieval methods like BM25 to improve search relevance and recall.\",\n",
    "        \"topic\": \"search\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Preparing {len(test_documents)} test documents...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add test documents to database (if not already present)\n",
    "import uuid\n",
    "\n",
    "test_doc_id = str(uuid.uuid4())\n",
    "\n",
    "for idx, doc in enumerate(test_documents):\n",
    "    dense_emb = get_embedding(doc['text'])\n",
    "    sparse_emb = get_sparse_embedding(doc['text'])\n",
    "    \n",
    "    chunk_id = rag.add_document_chunk(\n",
    "        project_id=PROJECT_ID,\n",
    "        document_id=test_doc_id,\n",
    "        document_name=\"comparison_test_doc\",\n",
    "        chunk_text=doc['text'],\n",
    "        chunk_index=idx,\n",
    "        dense_embedding=dense_emb,\n",
    "        sparse_embedding=sparse_emb,\n",
    "        topic=doc['topic'],\n",
    "        metadata={\"test_type\": \"comparison\"}\n",
    "    )\n",
    "\n",
    "print(\"Test documents added successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Search Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries with different characteristics\n",
    "test_queries = [\n",
    "    {\n",
    "        \"query\": \"What is PGVector and PostgreSQL?\",\n",
    "        \"type\": \"exact_match\",\n",
    "        \"description\": \"Query with exact keyword matches\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I store embeddings in a database for ML applications?\",\n",
    "        \"type\": \"semantic\",\n",
    "        \"description\": \"Semantic query without exact matches\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"cosine distance calculation vectors\",\n",
    "        \"type\": \"keyword_heavy\",\n",
    "        \"description\": \"Keyword-heavy query\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What are the benefits of combining different search methods?\",\n",
    "        \"type\": \"conceptual\",\n",
    "        \"description\": \"Conceptual query about hybrid approaches\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_search_results(query: str, limit: int = 5) -> Dict:\n",
    "    \"\"\"\n",
    "    Compare dense-only search with hybrid search\n",
    "    \"\"\"\n",
    "    # Get embeddings\n",
    "    dense_emb = get_embedding(query)\n",
    "    sparse_emb = get_sparse_embedding(query)\n",
    "    \n",
    "    # Dense-only search\n",
    "    start_time = time.time()\n",
    "    dense_results = rag.dense_search(\n",
    "        project_id=PROJECT_ID,\n",
    "        query_embedding=dense_emb,\n",
    "        limit=limit\n",
    "    )\n",
    "    dense_time = time.time() - start_time\n",
    "    \n",
    "    # Hybrid search\n",
    "    start_time = time.time()\n",
    "    hybrid_results = rag.hybrid_search(\n",
    "        project_id=PROJECT_ID,\n",
    "        query_dense=dense_emb,\n",
    "        query_sparse=sparse_emb,\n",
    "        limit=limit\n",
    "    )\n",
    "    hybrid_time = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        'query': query,\n",
    "        'dense_results': dense_results,\n",
    "        'hybrid_results': hybrid_results,\n",
    "        'dense_time': dense_time,\n",
    "        'hybrid_time': hybrid_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comparisons\n",
    "comparison_results = []\n",
    "\n",
    "for test_query in test_queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: {test_query['query']}\")\n",
    "    print(f\"Type: {test_query['type']} - {test_query['description']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    results = compare_search_results(test_query['query'])\n",
    "    results['query_type'] = test_query['type']\n",
    "    comparison_results.append(results)\n",
    "    \n",
    "    # Show top 3 results from each method\n",
    "    print(\"\\nDENSE SEARCH RESULTS:\")\n",
    "    for i, res in enumerate(results['dense_results'][:3]):\n",
    "        print(f\"{i+1}. [{res['distance']:.4f}] {res['chunk_text'][:100]}...\")\n",
    "    \n",
    "    print(\"\\nHYBRID SEARCH RESULTS:\")\n",
    "    for i, res in enumerate(results['hybrid_results'][:3]):\n",
    "        print(f\"{i+1}. [RRF: {res['rrf_score']:.4f}] {res['chunk_text'][:100]}...\")\n",
    "    \n",
    "    print(f\"\\nTiming: Dense={results['dense_time']:.3f}s, Hybrid={results['hybrid_time']:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overlap between search methods\n",
    "def calculate_overlap(dense_results: List, hybrid_results: List) -> float:\n",
    "    \"\"\"Calculate percentage of overlapping results\"\"\"\n",
    "    dense_ids = set(r['id'] for r in dense_results)\n",
    "    hybrid_ids = set(r['id'] for r in hybrid_results)\n",
    "    \n",
    "    overlap = len(dense_ids.intersection(hybrid_ids))\n",
    "    total_unique = len(dense_ids.union(hybrid_ids))\n",
    "    \n",
    "    return overlap / total_unique if total_unique > 0 else 0\n",
    "\n",
    "# Analyze results\n",
    "overlap_data = []\n",
    "for result in comparison_results:\n",
    "    overlap = calculate_overlap(result['dense_results'], result['hybrid_results'])\n",
    "    overlap_data.append({\n",
    "        'query_type': result['query_type'],\n",
    "        'overlap': overlap,\n",
    "        'query': result['query']\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df_overlap = pd.DataFrame(overlap_data)\n",
    "print(\"Result Overlap Analysis:\")\n",
    "print(df_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize overlap\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(df_overlap['query_type'], df_overlap['overlap'])\n",
    "plt.ylabel('Overlap Percentage')\n",
    "plt.xlabel('Query Type')\n",
    "plt.title('Result Overlap: Dense vs Hybrid Search')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, overlap in zip(bars, df_overlap['overlap']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "             f'{overlap:.2%}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare search times\n",
    "timing_data = []\n",
    "for result in comparison_results:\n",
    "    timing_data.append({\n",
    "        'query_type': result['query_type'],\n",
    "        'method': 'Dense',\n",
    "        'time': result['dense_time']\n",
    "    })\n",
    "    timing_data.append({\n",
    "        'query_type': result['query_type'],\n",
    "        'method': 'Hybrid',\n",
    "        'time': result['hybrid_time']\n",
    "    })\n",
    "\n",
    "df_timing = pd.DataFrame(timing_data)\n",
    "\n",
    "# Plot timing comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df_timing, x='query_type', y='time', hue='method')\n",
    "plt.ylabel('Search Time (seconds)')\n",
    "plt.xlabel('Query Type')\n",
    "plt.title('Search Performance: Dense vs Hybrid')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Dive: Ranking Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze ranking differences for a specific query\n",
    "analysis_query = \"How do I store embeddings in a database for ML applications?\"\n",
    "\n",
    "print(f\"Detailed Analysis for: '{analysis_query}'\\n\")\n",
    "\n",
    "results = compare_search_results(analysis_query, limit=10)\n",
    "\n",
    "# Create ranking comparison\n",
    "dense_ranking = {r['id']: i+1 for i, r in enumerate(results['dense_results'])}\n",
    "hybrid_ranking = {r['id']: i+1 for i, r in enumerate(results['hybrid_results'])}\n",
    "\n",
    "# Find documents that appear in different positions\n",
    "all_ids = set(dense_ranking.keys()).union(set(hybrid_ranking.keys()))\n",
    "\n",
    "ranking_comparison = []\n",
    "for doc_id in all_ids:\n",
    "    dense_rank = dense_ranking.get(doc_id, 'Not in top 10')\n",
    "    hybrid_rank = hybrid_ranking.get(doc_id, 'Not in top 10')\n",
    "    \n",
    "    # Get document text\n",
    "    doc_text = None\n",
    "    for r in results['dense_results'] + results['hybrid_results']:\n",
    "        if r['id'] == doc_id:\n",
    "            doc_text = r['chunk_text'][:100]\n",
    "            break\n",
    "    \n",
    "    ranking_comparison.append({\n",
    "        'doc_id': doc_id,\n",
    "        'text_preview': doc_text,\n",
    "        'dense_rank': dense_rank,\n",
    "        'hybrid_rank': hybrid_rank\n",
    "    })\n",
    "\n",
    "# Display ranking comparison\n",
    "df_ranking = pd.DataFrame(ranking_comparison)\n",
    "df_ranking = df_ranking.sort_values('hybrid_rank')\n",
    "print(df_ranking.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize key differences\n",
    "print(\"KEY INSIGHTS:\\n\")\n",
    "\n",
    "print(\"1. OVERLAP ANALYSIS:\")\n",
    "avg_overlap = df_overlap['overlap'].mean()\n",
    "print(f\"   - Average overlap between methods: {avg_overlap:.1%}\")\n",
    "print(f\"   - Lowest overlap for '{df_overlap.loc[df_overlap['overlap'].idxmin(), 'query_type']}' queries\")\n",
    "print(f\"   - Highest overlap for '{df_overlap.loc[df_overlap['overlap'].idxmax(), 'query_type']}' queries\")\n",
    "\n",
    "print(\"\\n2. PERFORMANCE:\")\n",
    "avg_dense_time = df_timing[df_timing['method'] == 'Dense']['time'].mean()\n",
    "avg_hybrid_time = df_timing[df_timing['method'] == 'Hybrid']['time'].mean()\n",
    "print(f\"   - Average dense search time: {avg_dense_time:.3f}s\")\n",
    "print(f\"   - Average hybrid search time: {avg_hybrid_time:.3f}s\")\n",
    "print(f\"   - Hybrid is {avg_hybrid_time/avg_dense_time:.1f}x slower\")\n",
    "\n",
    "print(\"\\n3. WHEN TO USE EACH METHOD:\")\n",
    "print(\"   - Dense Search: Best for semantic similarity, conceptual queries\")\n",
    "print(\"   - Hybrid Search: Best for keyword-heavy queries, exact matches, comprehensive recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Comparison Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_compare(query: str):\n",
    "    \"\"\"\n",
    "    Interactive tool to compare search methods\n",
    "    \"\"\"\n",
    "    results = compare_search_results(query, limit=5)\n",
    "    \n",
    "    # Create side-by-side comparison\n",
    "    print(f\"\\nQuery: '{query}'\\n\")\n",
    "    print(\"=\"*120)\n",
    "    print(f\"{'DENSE SEARCH':<60} | {'HYBRID SEARCH':<60}\")\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    for i in range(5):\n",
    "        # Dense result\n",
    "        if i < len(results['dense_results']):\n",
    "            d = results['dense_results'][i]\n",
    "            dense_text = f\"{i+1}. [{d['distance']:.3f}] {d['chunk_text'][:50]}...\"\n",
    "        else:\n",
    "            dense_text = \"\"\n",
    "        \n",
    "        # Hybrid result\n",
    "        if i < len(results['hybrid_results']):\n",
    "            h = results['hybrid_results'][i]\n",
    "            hybrid_text = f\"{i+1}. [RRF:{h['rrf_score']:.3f}] {h['chunk_text'][:50]}...\"\n",
    "        else:\n",
    "            hybrid_text = \"\"\n",
    "        \n",
    "        print(f\"{dense_text:<60} | {hybrid_text:<60}\")\n",
    "    \n",
    "    print(\"\\nMetrics:\")\n",
    "    print(f\"Search time: Dense={results['dense_time']:.3f}s, Hybrid={results['hybrid_time']:.3f}s\")\n",
    "    \n",
    "    overlap = calculate_overlap(results['dense_results'], results['hybrid_results'])\n",
    "    print(f\"Result overlap: {overlap:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own queries\n",
    "interactive_compare(\"What are vector databases?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another example\n",
    "interactive_compare(\"PostgreSQL JSON full-text search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "rag.close()\n",
    "print(\"Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
